{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados GradientBoosting:\n",
        "\n",
        "Accuracy:\n",
        "\n",
        "train = 0.8897283684115849\n",
        "          \n",
        "test = 0.7913669064748201"
      ],
      "metadata": {
        "id": "TAyFPaXbEu7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados GRU\n",
        "\n",
        "train_accuracy: 0.4947\n",
        "\n",
        "val_accuracy: 0.5000\n",
        "\n",
        "Test accuracy: 0.5093525052070618"
      ],
      "metadata": {
        "id": "WDzf4dL1Fg9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados LTSM\n",
        "\n",
        "train_accuracy: 0.5084\n",
        "\n",
        "val_accuracy: 0.5000\n",
        "\n",
        "Test accuracy: 0.49064749479293823"
      ],
      "metadata": {
        "id": "013m1GRkL2PP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados RNN:\n",
        "\n",
        "train_accuracy: 0.5145\n",
        "\n",
        "val_accuracy: 0.5469\n",
        "\n",
        "Test accuracy: 0.5093525052070618"
      ],
      "metadata": {
        "id": "u8oNfuHSFtLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados regresion logistica\n",
        "\n",
        "Accuracy_train for C=0.01: 0.809498111171074\n",
        "Accuracy_test for C=0.01: 0.7899280575539568\n",
        "\n",
        "Accuracy_train for C=0.05: 0.8314445044072675\n",
        "Accuracy_test for C=0.05: 0.8107913669064748\n",
        "\n",
        "Accuracy_train for C=0.25: 0.870300413743479\n",
        "Accuracy_test for C=0.25: 0.8366906474820144\n",
        "\n",
        "Accuracy_train for C=0.5: 0.8922468069796726\n",
        "Accuracy_test for C=0.5: 0.8482014388489209\n",
        "\n",
        "Accuracy_train for C=1: 0.9167116387839539\n",
        "Accuracy_test for C=1: 0.8539568345323741\n",
        "\n",
        "Accuracy_train for C=10: 0.9812915992084907\n",
        "Accuracy_test for C=10: 0.8719424460431655\n",
        "\n",
        "Accuracy_train for C=100: 0.9965821190861666\n",
        "Accuracy_test for C=100: 0.8669064748201439\n",
        "\n",
        "Accuracy_train for C=1000: 0.9976614499010613\n",
        "Accuracy_test for C=1000: 0.8568345323741007\n",
        "\n",
        "Accuracy_train for C=10000: 0.9980212268393596\n",
        "Accuracy_test for C=10000: 0.8532374100719424"
      ],
      "metadata": {
        "id": "HSymluPMEbSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusiones:\n",
        "\n",
        "Las conclusiones son que el modelo que mejor funciona es la regresion logistica. Despues de hacer un limpiado exhaustivo del corpus , intentando diferentes formas de limpiar el corpus y crear las stopwords, los resultados ante las variaciones es que son mejores en la regresion logistica y GradientBoosting. En los modelos de redes , los resultados son peores quiza porque el numero de registros no es suficiente para que la red aprenda mejor.Tambien he intentado distintas configuraciones de las redes , como por ejemplo dropout, pero los resultados no mejoraban. Tambien me gustaria probar con algunos parametros mas altos pero la capacidad de computacion subia mucho y en este caso no es posible.\n",
        "En cuanto al modelo elegido, creo que el mejor resultado es con C = 1 puesto que nos da un Accuracy de 91 en train y 85 en test. Se aprecia un peque√±o overfitting pero no es muy elevado.\n",
        "Se podia haber elegido otros valores pero me quedo con ese porque el resultado es alto y el overfitting no es mucho, en otros valores de parametros, el resultado el train es mejor pero el modelo generaliza peor.\n",
        "Tambien me gustan los resultados con C = 10 puesto que el accuracy es alto pero generaliza un poco peor , hay mas overfitting, pero la matriz de confusion es mejor que en el caso C = 1.\n",
        "\n",
        "En resumen , me quedo con la regresion logistica con valores de c= 1 o 10\n"
      ],
      "metadata": {
        "id": "QTkEvnCwGhqT"
      }
    }
  ]
}